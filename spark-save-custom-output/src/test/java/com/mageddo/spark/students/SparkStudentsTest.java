package com.mageddo.spark.students;

import com.mageddo.spark.students.dao.StudentDAO;
import com.mageddo.spark.students.vo.Student;
import org.apache.commons.lang3.time.StopWatch;
import org.junit.*;
import org.junit.rules.TemporaryFolder;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.BufferedOutputStream;
import java.io.File;
import java.io.FileOutputStream;
import java.io.OutputStream;
import java.nio.file.Files;
import java.sql.Connection;
import java.sql.SQLException;
import java.sql.Statement;
import java.util.List;
import java.util.Random;

import static com.mageddo.spark.students.DBUtils.getConnection;
import static com.mageddo.spark.students.SparkStudents.getMapper;
import static org.junit.Assert.*;

public class SparkStudentsTest {

	@Rule
	public TemporaryFolder folder = new TemporaryFolder();

	@BeforeClass
	public static void beforeAll() throws SQLException {

		// setup database gui
		System.setProperty("java.awt.headless", "false");
		org.hsqldb.util.DatabaseManagerSwing.main(new String[] {
			"--url",  "jdbc:hsqldb:mem:testdb", "--noexit"
		});

		// creating table structure
		try(Connection db = getConnection()){
			try(Statement stm = db.createStatement()){
				stm.execute("CREATE TABLE SCHOOL (\n" +
					"\tID INTEGER GENERATED BY DEFAULT AS IDENTITY(START WITH 1, INCREMENT BY 1) PRIMARY KEY,\n" +
					"\tNAME VARCHAR(255) UNIQUE \n" +
					")");
				stm.execute("CREATE TABLE STUDENT (\n" +
					"\tID INTEGER GENERATED BY DEFAULT AS IDENTITY(START WITH 1, INCREMENT BY 1) PRIMARY KEY,\n" +
					"\tSCHOOL_ID INTEGER,\n" +
					"\tNAME VARCHAR(255) UNIQUE \n" +
					")");
			}
			db.commit();
		}
	}

	@After
	public void after() throws SQLException {
		try(Connection connection = getConnection()){
			new StudentDAO(connection).truncateDB();
		}
	}


	@Test
	@Ignore
	public void groupAndTransport__PerformanceTest() throws Exception {

		final StopWatch stopWatch = new StopWatch();
		stopWatch.start();

		// creating a temp json to test
		final File jsonFile = folder.newFile("spark.tmp");
		final int students = 10_000_000;
		try(OutputStream out = new BufferedOutputStream(new FileOutputStream(jsonFile))){
			for(int i = students; i > 0; i--){
				final Student student = new Student(String.valueOf(new Random().nextInt(students)), String.valueOf(new Random().nextInt(students / 2)));
				out.write(getMapper().writeValueAsBytes(student));
				out.write('\n');
			}
		}

		new SparkStudents().groupAndTransport(jsonFile.getAbsolutePath());

		try(Connection connection = getConnection()){
			final StudentDAO dao = new StudentDAO(connection);
			System.out.printf("students=%d, schools=%d, time=%d%n", dao.countStudents(), dao.countSchools(), stopWatch.getTime());
		}
	}

	@Test
	public void groupAndTransport__RemoveStudentDuplicatesTest() throws Exception {

		// creating a temp json to test
		final File jsonFile = folder.newFile("spark.tmp");
		try(OutputStream out = new BufferedOutputStream(new FileOutputStream(jsonFile))){

			out.write(getMapper().writeValueAsBytes(new Student("Mark", "Walter Payton College Prep")));
			out.write('\n');

			out.write(getMapper().writeValueAsBytes(new Student("Mark", "Walter Payton College Prep")));
			out.write('\n');
		}

		new SparkStudents().groupAndTransport(jsonFile.getAbsolutePath());

		try(Connection connection = getConnection()){
			final List<Student> students = new StudentDAO(connection).findAll();
			Assert.assertEquals(1, students.size());
			Assert.assertEquals("Mark", students.get(0).name);
		}
	}

	@Test
	public void groupAndTransport__TwoStudentsWithSameSchoolTest() throws Exception {

		// creating a temp json to test
		final File jsonFile = folder.newFile("spark.tmp");
		try(OutputStream out = new BufferedOutputStream(new FileOutputStream(jsonFile))){

			out.write(getMapper().writeValueAsBytes(new Student("Mark", "Walter Payton College Prep")));
			out.write('\n');

			out.write(getMapper().writeValueAsBytes(new Student("Maria", "Walter Payton College Prep")));
			out.write('\n');
		}

		new SparkStudents().groupAndTransport(jsonFile.getAbsolutePath());

		try(Connection connection = getConnection()){
			final List<Student> students = new StudentDAO(connection).findAll();
			Assert.assertEquals(2, students.size());

			Assert.assertEquals("Maria", students.get(0).name);
			Assert.assertEquals("Mark", students.get(1).name);

			Assert.assertEquals("Walter Payton College Prep", students.get(0).schoolName);
			Assert.assertEquals("Walter Payton College Prep", students.get(1).schoolName);
		}
	}

	@Test
	public void groupAndTransport__TwoStudentsAndTwoSchools() throws Exception {

		// creating a temp json to test
		final File jsonFile = folder.newFile("spark.tmp");
		try(OutputStream out = new BufferedOutputStream(new FileOutputStream(jsonFile))){

			out.write(getMapper().writeValueAsBytes(new Student("Mark", "Walter Payton College Prep")));
			out.write('\n');

			out.write(getMapper().writeValueAsBytes(new Student("Maria", "Northside College Preparatory High School")));
			out.write('\n');
		}

		new SparkStudents().groupAndTransport(jsonFile.getAbsolutePath());

		try(Connection connection = getConnection()){
			final List<Student> students = new StudentDAO(connection).findAll();
			Assert.assertEquals(2, students.size());

			Assert.assertEquals("Maria", students.get(0).name);
			Assert.assertEquals("Mark", students.get(1).name);

			Assert.assertEquals("Northside College Preparatory High School", students.get(0).schoolName);
			Assert.assertEquals("Walter Payton College Prep", students.get(1).schoolName);
		}
	}


}
